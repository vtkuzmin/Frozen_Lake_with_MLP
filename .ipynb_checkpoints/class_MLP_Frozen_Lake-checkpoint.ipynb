{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "def derivative_sigmoid(x):\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "\n",
    "def derivative_relu(x):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "        \n",
    "def identity(x):\n",
    "        return x\n",
    "    \n",
    "def derivative_identity(x):\n",
    "        return 1\n",
    "    \n",
    "activation = {'sigmoid': sigmoid, 'relu': relu, 'linear': identity}\n",
    "derivatives = {'sigmoid': derivative_sigmoid, 'relu': derivative_relu,  'identity': derivative_identity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP:    \n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_output, f_hidden, f_output, bias = True):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.f1 = activation[f_hidden]\n",
    "        self.f2 = activation[f_output]\n",
    "        self.bias = int(bias)\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        self.W1 = np.random.uniform(-1/(2*self.n_input), 1/(2*self.n_input), \n",
    "                                    size = (self.n_input+self.bias, self.n_hidden))\n",
    "        self.W2 = np.random.uniform(-1/(2*self.n_hidden), 1/(2*self.n_hidden), \n",
    "                                    size = (self.n_hidden+self.bias, self.n_output))\n",
    "        \n",
    "    # Forward propagation \n",
    "    # x - input vector [L,n]\n",
    "    # W1 - weight matrix [n,H], where H - number of hidden units\n",
    "    # f1 - activation function of the hidden layer\n",
    "    # W2 - weight matrix [H,m], where m - number of output units\n",
    "    # f2 - activation function of the output layer\n",
    "    # U - output of the hidden layer, A - output of the network\n",
    "    def feed_forward(self, X):\n",
    "        \n",
    "        if not isinstance(X, np.ndarray):\n",
    "            print(\"X is not a np.array\")\n",
    "            return _\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "            \n",
    "        if self.bias:\n",
    "            b = np.array([-1 for i in range(X.shape[0])])\n",
    "            b  = b[:,np.newaxis]\n",
    "            X = np.hstack((b, X))\n",
    "        \n",
    "        u0 = np.dot(X, self.W1) # 1 x H\n",
    "        U = self.f1(u0) # 1 x H\n",
    "        \n",
    "        if self.bias:\n",
    "            b = np.array([-1 for i in range(U.shape[0])])\n",
    "            b  = b[:,np.newaxis]\n",
    "            U1 = np.hstack((b, U)) # 1 x H+1\n",
    "            \n",
    "        a0 = np.dot(U1,self.W2) # 1 x M\n",
    "        A = self.f2(a0) # 1 x M\n",
    "        \n",
    "        return X, u0, U, U1, a0, A\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _,_,_,_,_,y = self.feed_forward(X)\n",
    "        return y\n",
    "    \n",
    "    def calculate_error(self, X, y):\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[:,np.newaxis]\n",
    "            \n",
    "        l = X.shape[0]\n",
    "        \n",
    "        X_pred = self.predict(X)\n",
    "        Q = 0\n",
    "        for i in range(l):\n",
    "            q_i = 1/2*np.sum((X_pred[i]-y[i])**2)\n",
    "            Q += q_i\n",
    "        return Q/l\n",
    "        \n",
    "    \n",
    "    def training(self, X, y,n = 0.5, eps = 10e-9, verbose = False):\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[:,np.newaxis]\n",
    "            \n",
    "        l = X.shape[0]\n",
    "        \n",
    "        X_pred = self.predict(X)\n",
    "        \n",
    "        # initialize the error\n",
    "        Q = 0\n",
    "        for i in range(l):\n",
    "            q_i = 1/2*np.sum((X_pred[i]-y[i])**2)\n",
    "            Q += q_i\n",
    "        Q = Q/l\n",
    "        \n",
    "        while(True):\n",
    "            i = np.random.randint(0,l)\n",
    "            #forward:\n",
    "            X_bias, u0, u, u1, a0, a = self.feed_forward(X[i])\n",
    "            e_m = a - y[i] # 1 x M\n",
    "            q_i = np.sum(e_m**2)\n",
    "            #backward:\n",
    "            e_h = np.dot(e_m * derivatives[self.f2](a0), np.transpose(self.W2[1:,:])) # 1 x H \n",
    "            #grad_step:\n",
    "            self.W2 -= n * np.dot(np.transpose(u1), e_m*derivatives[self.f2](a0))\n",
    "            self.W1 -= n * np.dot(np.transpose(X_bias), e_h*derivatives[self.f1](u0))\n",
    "            \n",
    "            Q_old = Q\n",
    "            Q = (l-1)/l*Q + 1/l*q_i\n",
    "            \n",
    "            if np.abs(Q-Q_old)<eps:\n",
    "                break\n",
    "        if verbose:\n",
    "            print(\"Train error: \",Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-10-05 21:28:52,583] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_RL = MLP(16, 16, 4, 'relu', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_episodes = 2000\n",
    "gamma = 0.99 #since it may take several moves to goal, making gamma high\n",
    "epsilon = 0.1\n",
    "#create list to contain total rewards\n",
    "jList = []\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Network\n",
    "    while 1: #j < 99:\n",
    "        #j+=1\n",
    "        qval = model_RL.predict(np.identity(16)[s:s+1])\n",
    "        if (np.random.rand(1) < epsilon): #choose random action\n",
    "            action = env.action_space.sample()\n",
    "        else: #choose best action from Q(s,a) values\n",
    "            action = (np.argmax(qval))\n",
    "        s1, r, d, _ = env.step(action)\n",
    "        Q1 = model_RL.predict(np.identity(16)[s1:s1+1])\n",
    "        maxQ1 = np.max(Q1)\n",
    "        targetQ = qval\n",
    "        targetQ[0,action] = r + gamma*maxQ1\n",
    "        #Train our network using target and predicted Q values\n",
    "        model_RL.training(np.identity(16)[s:s+1], targetQ, n = 0.1)\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            #Reduce chance of random action as we train the model.\n",
    "            epsilon = 1./((i/50) + 10)\n",
    "            break\n",
    "        \n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of succesful episodes: 0.0365\n"
     ]
    }
   ],
   "source": [
    "print (\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116081780>]"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4ik0P8HQXI3VdeHwLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d93940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Покажем, что сеть работает__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # we only take the first two features.\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_new = np.zeros((len(y),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    y_new[i,y[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MLP(4,8,3, 'sigmoid', 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.training(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = []\n",
    "y_test2 = []\n",
    "for i in range(len(X_test)):\n",
    "    y_pred2.append(np.argmax(y_pred[i]))\n",
    "    y_test2.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1, 0,\n",
       "       2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1,\n",
       "       1, 2, 1, 2])"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#после первого запуска\n",
    "np.array(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1,\n",
       "       2, 2, 1, 2])"
      ]
     },
     "execution_count": 1037,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тест\n",
    "np.array(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0,\n",
       "       2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1,\n",
       "       2, 2, 1, 2])"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#после второго запуска - 100% точность \n",
    "np.array(y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
